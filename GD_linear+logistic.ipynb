{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Batch GD\n",
    "def gradientDescent(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    J_history = np.ones((iterations,1))\n",
    "    \n",
    "    for i in range(0,iterations):\n",
    "        theta = theta - (alpha/m)*(X.T)@(X@theta-y)\n",
    "        \n",
    "        J_history[i] = computeCost(X,y,theta)\n",
    "    return [theta, J_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Batch GD\n",
    "def gradientDescent(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    J_history = np.ones((iterations,1))\n",
    "    \n",
    "    for i in range(0,iterations):\n",
    "        theta = theta - (alpha/m)*(X.T)@(sigmoid(X@theta)-y)\n",
    "\n",
    "        J_history[i] = computeCost(X,y,theta)\n",
    "    return [theta, J_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Mini-Batch GD\n",
    "def MBGD(X, y, theta, alpha, iterations, batch_size=16):\n",
    "    m = len(y)\n",
    "    J_history = np.ones((iterations,1))\n",
    "    n_batches = int(m/batch_size)\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        shuffle = np.random.permutation(m) #shuffling the indexes so you get randomized batches\n",
    "        X = X[shuffle] #applying those shuffled indexes to X\n",
    "        y = y[shuffle] #applying those shuffled indexes to y\n",
    "        \n",
    "        for i in range(0,m, batch_size):\n",
    "            X_i = X[i:i+batch_size] #creating and applying to X mini batch to calculate theta\n",
    "            y_i = y[i:i+batch_size] #creating and applying to y mini batch to calculate theta\n",
    "            prediction = X_i@theta\n",
    "            theta = theta -(alpha/m)*(X_i.T@(prediction - y_i))\n",
    "        J_history[it] = computeCost(X,y,theta)\n",
    "    return [theta, J_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Batch GD with Regularization\n",
    "def gradientDescentReg(X, y, theta, lamb, alpha, iterations):\n",
    "    m = len(y)\n",
    "    J_history = np.ones((iterations,1))\n",
    "    lr = theta.shape[0]\n",
    "    \n",
    "    for i in range(0,iterations):\n",
    "        theta[0] = theta[0] - (alpha/m)*(X[:,0].T)@(sigmoid(X@theta)-y)\n",
    "        theta[1:lr] = theta[1:lr] - (alpha/m)*(X[:,1:lr].T)@(sigmoid(X@theta)-y)+((alpha*lamb/m)*theta[1:lr])\n",
    "\n",
    "        J_history[i] = computeCostReg(X,y,theta,lamb)\n",
    "    return [theta, J_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Mini-Batch GD with Regularization\n",
    "def MBGDReg(X, y, theta, lamb, alpha, iterations, batch_size=16):\n",
    "    m = len(y)\n",
    "    J_history = np.ones((iterations,1))\n",
    "    n_batches = int(m/batch_size)\n",
    "    lr = theta.shape[0]\n",
    "\n",
    "    for it in range(iterations):\n",
    "        shuffle = np.random.permutation(m) #shuffling the indexes so you get randomized batches\n",
    "        X = X[shuffle] #applying those shuffled indexes to X\n",
    "        y = y[shuffle] #applying those shuffled indexes to y\n",
    "        \n",
    "        for i in range(0,m, batch_size):\n",
    "            X_i = X[i:i+batch_size] #creating and applying to X mini batch to calculate theta\n",
    "            y_i = y[i:i+batch_size] #creating and applying to y mini batch to calculate theta\n",
    "            \n",
    "            prediction = sigmoid(X_i@theta)\n",
    "            \n",
    "            theta[0] = theta[0] - (alpha/m)*(X_i[:,0].T)@(prediction-y_i)\n",
    "            theta[1:lr] = theta[1:lr] - (alpha/m)*(X_i[:,1:lr].T)@(prediction-y_i)+((alpha*lamb/m)*theta[1:lr])\n",
    "        \n",
    "        J_history[it] = computeCostReg(X,y,theta,lamb)\n",
    "    return [theta, J_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliar Function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
